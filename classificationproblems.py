# -*- coding: utf-8 -*-
"""Assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x2u8QI-YI07wbgJdSG_pHvmgzWUudw9D
"""

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
datasheet = pd.read_excel('/content/gdrive/MyDrive/Dataset2Use_Assignment2.xlsx')

#printing for each year the number of not bankrupt and bankrupt companies
print(datasheet.groupby(['ΕΤΟΣ','ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)']).size().unstack())

#printing for each metric the mean, min & max values for each year
print(datasheet.groupby('ΕΤΟΣ').agg({'365* ( Β.Υ / Κοστ.Πωλ )': ['mean', 'min', 'max']}))
print(datasheet.groupby('ΕΤΟΣ').agg({'Λειτ.Αποτ/Συν.Ενεργ. (ROA)': ['mean', 'min', 'max']}))
print(datasheet.groupby('ΕΤΟΣ').agg({'ΧΡΗΜ.ΔΑΠΑΝΕΣ / ΠΩΛΗΣΕΙΣ': ['mean', 'min', 'max']}))
print(datasheet.groupby('ΕΤΟΣ').agg({' ΠΡΑΓΜΑΤΙΚΗ ΡΕΥΣΤΟΤΗΤΑ :  (ΚΕ-ΑΠΟΘΕΜΑΤΑ) / Β.Υ': ['mean', 'min', 'max']}))
print(datasheet.groupby('ΕΤΟΣ').agg({'(ΑΠΑΙΤ.*365) / ΠΩΛ.': ['mean', 'min', 'max']}))
print(datasheet.groupby('ΕΤΟΣ').agg({'Συν.Υποχρ/Συν.Ενεργ': ['mean', 'min', 'max']}))
print(datasheet.groupby('ΕΤΟΣ').agg({'Διάρκεια Παραμονής Αποθεμάτων': ['mean', 'min', 'max']}))
print(datasheet.groupby('ΕΤΟΣ').agg({'Λογαριθμος Προσωπικού': ['mean', 'min', 'max']}))

#normalizing the datasheet (no normaliziation needed in the binary columns and year)
from sklearn.preprocessing import MinMaxScaler
cols_to_norm = ['365* ( Β.Υ / Κοστ.Πωλ )','Λειτ.Αποτ/Συν.Ενεργ. (ROA)','ΧΡΗΜ.ΔΑΠΑΝΕΣ / ΠΩΛΗΣΕΙΣ',' ΠΡΑΓΜΑΤΙΚΗ ΡΕΥΣΤΟΤΗΤΑ :  (ΚΕ-ΑΠΟΘΕΜΑΤΑ) / Β.Υ','(ΑΠΑΙΤ.*365) / ΠΩΛ.','Συν.Υποχρ/Συν.Ενεργ','Διάρκεια Παραμονής Αποθεμάτων','Λογαριθμος Προσωπικού','ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)']
datasheet[cols_to_norm] = MinMaxScaler().fit_transform(datasheet[cols_to_norm])

# Split dataset into training set, test set & validation set
from sklearn.model_selection import train_test_split

feature_cols = ['365* ( Β.Υ / Κοστ.Πωλ )','Λειτ.Αποτ/Συν.Ενεργ. (ROA)','ΧΡΗΜ.ΔΑΠΑΝΕΣ / ΠΩΛΗΣΕΙΣ',' ΠΡΑΓΜΑΤΙΚΗ ΡΕΥΣΤΟΤΗΤΑ :  (ΚΕ-ΑΠΟΘΕΜΑΤΑ) / Β.Υ','(ΑΠΑΙΤ.*365) / ΠΩΛ.','Συν.Υποχρ/Συν.Ενεργ','Διάρκεια Παραμονής Αποθεμάτων','Λογαριθμος Προσωπικού','ΕΝΔΕΙΞΗ ΕΞΑΓΩΓΩΝ','ΕΝΔΕΙΞΗ ΕΙΣΑΓΩΓΩΝ','ΕΝΔΕΙΞΗ ΑΝΤΙΠΡΟΣΩΠΕΙΩΝ','ΕΤΟΣ']
X = datasheet[feature_cols] 
y = datasheet['ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training set, 30% test and val sets
X_val, X_test, y_val, y_test  = train_test_split(X_test, y_test, test_size=0.66, random_state=1) # 30*0.66 = 20% test set, rest goes in validation set

#print number of ok companies and bankrupt companies in each set
ok_train = y_train.value_counts()[0]
bankrupt_train = y_train.value_counts()[1]
ok_test = y_test.value_counts()[0]
bankrupt_test = y_test.value_counts()[1]
print("The train set has " + str(ok_train) + " healthy companies and " + str(bankrupt_train) +" bankrupt companies")
print("The test set has " + str(ok_test) + " healthy companies and " + str(bankrupt_test) +" bankrupt companies")

#imbalanced dataset - oversampling on the training set
from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train, y_train)

#Decision Tree model
from sklearn.tree import DecisionTreeClassifier

#intiate the classifier
clf = DecisionTreeClassifier()

#train the classifier
clf.fit(X_res, y_res)

#use the trained classifier to estimate the outputs 
DTM_predicted_output_values_train = clf.predict(X_res)
DTM_predicted_output_values_test = clf.predict(X_test)

#Logistic Regression
from sklearn import linear_model 

#initiate the classifier
clf = linear_model.LogisticRegression()

#train the classifier
clf.fit(X_res, y_res)

#use the trained classifier to estimate the outputs 
LR_predicted_output_values_train = clf.predict(X_res)
LR_predicted_output_values_test = clf.predict(X_test)

#k-Nearest Neighbors
from sklearn.neighbors import KNeighborsClassifier

#intiate the classifier
clf = KNeighborsClassifier(n_neighbors=4)

#train the classifier
clf.fit(X_res, y_res)

#use the trained classifier to estimate the outputs 
KNN_predicted_output_values_train = clf.predict(X_res)
KNN_predicted_output_values_test = clf.predict(X_test)

#Support Vector Machines
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_res, y_res)

#use the trained classifier to estimate the outputs 
SVM_predicted_output_values_train = clf.predict(X_res)
SVM_predicted_output_values_test = clf.predict(X_test)

#make the confusion matrices
from sklearn.metrics import confusion_matrix
DTM_cf_matrix_train = confusion_matrix(y_res,DTM_predicted_output_values_train)
DTM_cf_matrix_test = confusion_matrix(y_test,DTM_predicted_output_values_test)

LR_cf_matrix_train = confusion_matrix(y_res,LR_predicted_output_values_train)
LR_cf_matrix_test = confusion_matrix(y_test,LR_predicted_output_values_test)

KNN_cf_matrix_train = confusion_matrix(y_res,KNN_predicted_output_values_train)
KNN_cf_matrix_test = confusion_matrix(y_test,KNN_predicted_output_values_test)

SVM_cf_matrix_train = confusion_matrix(y_res,SVM_predicted_output_values_train)
SVM_cf_matrix_test = confusion_matrix(y_test,SVM_predicted_output_values_test)

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
#function for plotting the confusion matrices

def cf_plot(cf_matrix, class_names):
  #class names: list of the form ['a','b','b',etc]
  #keep two decimals
  group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
  group_percentages = ["{0:.2%}".format(value) for value in
                      cf_matrix.flatten()/np.sum(cf_matrix)]

  labels = [f"{v1}\n{v2}\n" for v1, v2 in
            zip(group_counts,group_percentages)]

  labels = np.asarray(labels).reshape(2,2)

  ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')

  ax.set_title('Seaborn Confusion Matrix with labels\n\n');
  ax.set_xlabel('\nPredicted Bankruptcy')
  ax.set_ylabel('Actual Bankruptcy ');

  ## Ticket labels - List must be in alphabetical order
  ax.xaxis.set_ticklabels(class_names)
  ax.yaxis.set_ticklabels(class_names)
  # ax.xaxis.set_ticklabels(['Setosa','Versicolor', 'Virginia'])
  # ax.yaxis.set_ticklabels(['Setosa','Versicolor', 'Virginia'])

  ## Display the visualization of the Confusion Matrix.
  plt.show()

#print the confusion matrices
cf_plot(DTM_cf_matrix_train,['ok','bankrupt'])
cf_plot(DTM_cf_matrix_test,['ok','bankrupt'])
cf_plot(LR_cf_matrix_train,['ok','bankrupt'])
cf_plot(LR_cf_matrix_test,['ok','bankrupt'])
cf_plot(KNN_cf_matrix_train,['ok','bankrupt'])
cf_plot(KNN_cf_matrix_test,['ok','bankrupt'])
cf_plot(SVM_cf_matrix_train,['ok','bankrupt'])
cf_plot(SVM_cf_matrix_test,['ok','bankrupt'])

from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score

#fucntion to print and get the accuracy, precision, recall & F1 for each clasifier
def modelAssessment (outputData,preditctedOutputData,returnText):
  acc = accuracy_score(outputData,preditctedOutputData )
  pre = precision_score(outputData,preditctedOutputData,average='macro',zero_division=0)
  rec = recall_score(outputData,preditctedOutputData,average='macro')
  f1 =f1_score(outputData,preditctedOutputData,average='macro')
  print('Acc, Pre, Rec, F1 scores for ' + returnText + ' are:', '{:.2f} '.format(acc), '{:.2f} '.format(pre), '{:.2f} '.format(rec), '{:.2f} '.format(f1))
  return acc, pre, rec, f1

DTM_train_acc, DTM_train_pre, DTM_train_rec, DTM_train_f1 = modelAssessment(y_res,DTM_predicted_output_values_train,"DTM on training data")
DTM_test_acc, DTM_test_pre, DTM_test_rec, DTM_test_f1 = modelAssessment(y_test,DTM_predicted_output_values_test,"DTM on testing data")

LR_train_acc, LR_train_pre, LR_train_rec, LR_train_f1 = modelAssessment(y_res,LR_predicted_output_values_train,"LR on training data")
LR_test_acc, LR_test_pre, LR_test_rec, LR_test_f1 = modelAssessment(y_test,LR_predicted_output_values_test,"LR on testing data")

KNN_train_acc, KNN_train_pre, KNN_train_rec, KNN_train_f1 = modelAssessment(y_res,KNN_predicted_output_values_train,"KNN on training data")
KNN_test_acc, KNN_test_pre, KNN_test_rec, KNN_test_f1 = modelAssessment(y_test,KNN_predicted_output_values_test,"KNN on testing data")

SVM_train_acc, SVM_train_pre, SVM_train_rec, SVM_train_f1 = modelAssessment(y_res,SVM_predicted_output_values_train,"SVM on training data")
SVM_test_acc, SVM_test_pre, SVM_test_rec, SVM_test_f1 = modelAssessment(y_test,SVM_predicted_output_values_test,"SVM on testing data")

#function to get the True Positives, False Positives, True Negatives & False Negatives for each classifier

def perf_measure(CM):
    TP = CM[0][0]
    FP = CM[1][0]
    TN = CM[1][1]
    FN = CM[0][1]

    return(TP, FP, TN, FN)
    
TP_DTM_train, FP_DTM_train, TN_DTM_train, FN_DTM_train = perf_measure(DTM_cf_matrix_train)
TP_DTM_test, FP_DTM_test, TN_DTM_test, FN_DTM_test = perf_measure(DTM_cf_matrix_test)

TP_LR_train, FP_LR_train, TN_LR_train, FN_LR_train = perf_measure(LR_cf_matrix_train)
TP_LR_test, FP_LR_test, TN_LR_test, FN_LR_test = perf_measure(LR_cf_matrix_test)

TP_KNN_train, FP_KNN_train, TN_KNN_train, FN_KNN_train = perf_measure(KNN_cf_matrix_train)
TP_KNN_test, FP_KNN_test, TN_KNN_test, FN_KNN_test = perf_measure(KNN_cf_matrix_test)

TP_SVM_train, FP_SVM_train, TN_SVM_train, FN_SVM_train = perf_measure(SVM_cf_matrix_train)
TP_SVM_test, FP_SVM_test, TN_SVM_test, FN_SVM_test = perf_measure(SVM_cf_matrix_test)

#create the csv file with all the results
import csv
header = ["Classifier Name", "Training or test set","Number of training samples","Number of non-healthy companies in training sample","TP","TN","FP","FN","Precision","Recall","F1 Score","Accuracy"]
y_train_length = len(y_train)
with open('assignment2output.csv', 'w', newline='') as file:
  writer = csv.writer(file)
  writer.writerow(header)
  writer.writerow(["DTM","Training",y_train_length,bankrupt_train,TP_DTM_train,TN_DTM_train,FP_DTM_train,FN_DTM_train,DTM_train_pre,DTM_train_rec,DTM_train_f1,DTM_train_acc])
  writer.writerow(["DTM","Testing",y_train_length,bankrupt_train,TP_DTM_test,TN_DTM_test,FP_DTM_test,FN_DTM_test,DTM_test_pre,DTM_test_rec,DTM_test_f1,DTM_test_acc])
  writer.writerow(["LR","Training",y_train_length,bankrupt_train,TP_LR_train,TN_LR_train,FP_LR_train,FN_LR_train,LR_train_pre,LR_train_rec,LR_train_f1,LR_train_acc])
  writer.writerow(["LR","Testing",y_train_length,bankrupt_train,TP_LR_test,TN_LR_test,FP_LR_test,FN_LR_test,LR_test_pre,LR_test_rec,LR_test_f1,LR_test_acc])
  writer.writerow(["KNN","Training",y_train_length,bankrupt_train,TP_KNN_train,TN_KNN_train,FP_KNN_train,FN_KNN_train,KNN_train_pre,KNN_train_rec,KNN_train_f1,KNN_train_acc])
  writer.writerow(["KNN","Testing",y_train_length,bankrupt_train,TP_KNN_test,TN_KNN_test,FP_KNN_test,FN_KNN_test,KNN_test_pre,KNN_test_rec,KNN_test_f1,KNN_test_acc])
  writer.writerow(["SVM","Training",y_train_length,bankrupt_train,TP_SVM_train,TN_SVM_train,FP_SVM_train,FN_SVM_train,SVM_train_pre,SVM_train_rec,SVM_train_f1,SVM_train_acc])
  writer.writerow(["SVM","Testing",y_train_length,bankrupt_train,TP_SVM_test,TN_SVM_test,FP_SVM_test,FN_SVM_test,SVM_test_pre,SVM_test_rec,SVM_test_f1,SVM_test_acc])

